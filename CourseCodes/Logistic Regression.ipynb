{"cells":[{"cell_type":"markdown","metadata":{"id":"mELOi-lUIMF1"},"source":["# Logistic Regression"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1727802773343,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"sG77NaXJIMF-","outputId":"dc843581-62f1-4e0a-f8e9-7de99259d0e5"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"X = data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"InMichelin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Restaurant Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"212\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Food\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 17,\n        \"max\": 23,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          19,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Decor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 12,\n        \"max\": 23,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          17,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 16,\n        \"max\": 21,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          19,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 24,\n        \"max\": 52,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          43,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe"},"text/html":["\n","  <div id=\"df-a1627a05-3c32-44d4-b843-3cb9c220b233\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>InMichelin</th>\n","      <th>Restaurant Name</th>\n","      <th>Food</th>\n","      <th>Decor</th>\n","      <th>Service</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>14 Wall Street</td>\n","      <td>19</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>212</td>\n","      <td>17</td>\n","      <td>17</td>\n","      <td>16</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>26 Seats</td>\n","      <td>23</td>\n","      <td>17</td>\n","      <td>21</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>44</td>\n","      <td>19</td>\n","      <td>23</td>\n","      <td>16</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>23</td>\n","      <td>12</td>\n","      <td>19</td>\n","      <td>24</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1627a05-3c32-44d4-b843-3cb9c220b233')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a1627a05-3c32-44d4-b843-3cb9c220b233 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a1627a05-3c32-44d4-b843-3cb9c220b233');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f8c4ce99-0f7b-4be1-bc26-6f428d37d3cb\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f8c4ce99-0f7b-4be1-bc26-6f428d37d3cb')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f8c4ce99-0f7b-4be1-bc26-6f428d37d3cb button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["   InMichelin Restaurant Name  Food  Decor  Service  Price\n","0           0  14 Wall Street    19     20       19     50\n","1           0             212    17     17       16     43\n","2           0        26 Seats    23     17       21     35\n","3           1              44    19     23       16     52\n","4           0               A    23     12       19     24"]},"metadata":{},"output_type":"display_data"}],"source":["# Import some example data\n","import pandas as pd\n","data = pd.read_csv(\"http://gattonweb.uky.edu/sheather/book/docs/datasets/MichelinNY.csv\", encoding=\"latin_1\")\n","display(data.head())\n","\n","# Update data to set up for train test split, remove Restaurant Name column\n","data = data.loc[:, data.columns != 'Restaurant Name']\n","y = data['InMichelin'] # whether or not a restaurant is in the Michelin guide\n","X = data.loc[:, data.columns != 'InMichelin']"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1727802895675,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"M387P_MHIMGV","outputId":"3945b0f8-b2ff-4884-f3ae-a92ada3a7fec"},"outputs":[{"name":"stdout","output_type":"stream","text":["logreg.coef_: [[ 0.3817785   0.07436958 -0.15689     0.08189899]]\n","Training set score: 0.797\n","Test set score: 0.780\n","logreg.predict: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n"," 1 1 1 1]\n"]}],"source":["# Set up training and test data\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","\n","# random_state ensures same data will be generated for example each time\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","\n","# Set penalty to none since we are starting with non penalized logit, L1 and L2 are other options\n","logreg = LogisticRegression(penalty=None).fit(X_train, y_train)\n","\n","print(\"logreg.coef_: {}\".format(logreg.coef_))\n","print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n","print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n","\n","predicted_vals = logreg.predict(X_test) # predictions for y\n","print(\"logreg.predict: {}\".format(predicted_vals))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182,"status":"ok","timestamp":1727802918686,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"DsGxhRx9E_SL","outputId":"de57ec71-a104-4d3a-ad0b-2300aac23c1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["logreg.predict_proba: [[0.85255621 0.14744379]\n"," [0.8446288  0.1553712 ]\n"," [0.67683217 0.32316783]\n"," [0.13743201 0.86256799]\n"," [0.86699615 0.13300385]\n"," [0.86173679 0.13826321]\n"," [0.83068042 0.16931958]\n"," [0.89753411 0.10246589]\n"," [0.53906147 0.46093853]\n"," [0.79534094 0.20465906]\n"," [0.77504428 0.22495572]\n"," [0.86070764 0.13929236]\n"," [0.73355788 0.26644212]\n"," [0.10933611 0.89066389]\n"," [0.00766565 0.99233435]\n"," [0.92517214 0.07482786]\n"," [0.85073211 0.14926789]\n"," [0.89511686 0.10488314]\n"," [0.72394995 0.27605005]\n"," [0.1360114  0.8639886 ]\n"," [0.63012902 0.36987098]\n"," [0.88145938 0.11854062]\n"," [0.03744012 0.96255988]\n"," [0.78424495 0.21575505]\n"," [0.90184835 0.09815165]\n"," [0.8390162  0.1609838 ]\n"," [0.82970658 0.17029342]\n"," [0.80844509 0.19155491]\n"," [0.86331046 0.13668954]\n"," [0.11763491 0.88236509]\n"," [0.55370252 0.44629748]\n"," [0.08942718 0.91057282]\n"," [0.31926949 0.68073051]\n"," [0.52149073 0.47850927]\n"," [0.73736448 0.26263552]\n"," [0.78091594 0.21908406]\n"," [0.58705592 0.41294408]\n"," [0.0075136  0.9924864 ]\n"," [0.1653582  0.8346418 ]\n"," [0.304658   0.695342  ]\n"," [0.46890835 0.53109165]]\n"]}],"source":["# You can see the raw probabilities that went into determining the y predictions\n","predicted_prob = logreg.predict_proba(X_test)\n","print(\"logreg.predict_proba: {}\".format(predicted_prob))"]},{"cell_type":"markdown","metadata":{"id":"fODA7tsxIMHI"},"source":["## Logistic Regression in statsmodels package"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1727803000917,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"igNMntjKIMHN","outputId":"30287eba-7f6e-4fb7-ee4c-6614d02e9ef3"},"outputs":[{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>Generalized Linear Model Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>      <td>InMichelin</td>    <th>  No. Observations:  </th>  <td>   123</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   118</td> \n","</tr>\n","<tr>\n","  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     4</td> \n","</tr>\n","<tr>\n","  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -57.266</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>            <td>Tue, 01 Oct 2024</td> <th>  Deviance:          </th> <td>  114.53</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                <td>17:16:40</td>     <th>  Pearson chi2:      </th>  <td>  254.</td> \n","</tr>\n","<tr>\n","  <th>No. Iterations:</th>          <td>6</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.3534</td> \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th>   <td>  -10.6490</td> <td>    2.588</td> <td>   -4.115</td> <td> 0.000</td> <td>  -15.722</td> <td>   -5.576</td>\n","</tr>\n","<tr>\n","  <th>Food</th>    <td>    0.3818</td> <td>    0.148</td> <td>    2.572</td> <td> 0.010</td> <td>    0.091</td> <td>    0.673</td>\n","</tr>\n","<tr>\n","  <th>Decor</th>   <td>    0.0743</td> <td>    0.103</td> <td>    0.720</td> <td> 0.471</td> <td>   -0.128</td> <td>    0.277</td>\n","</tr>\n","<tr>\n","  <th>Service</th> <td>   -0.1569</td> <td>    0.147</td> <td>   -1.070</td> <td> 0.285</td> <td>   -0.444</td> <td>    0.131</td>\n","</tr>\n","<tr>\n","  <th>Price</th>   <td>    0.0819</td> <td>    0.036</td> <td>    2.269</td> <td> 0.023</td> <td>    0.011</td> <td>    0.153</td>\n","</tr>\n","</table>"],"text/latex":["\\begin{center}\n","\\begin{tabular}{lclc}\n","\\toprule\n","\\textbf{Dep. Variable:}   &    InMichelin    & \\textbf{  No. Observations:  } &      123    \\\\\n","\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &      118    \\\\\n","\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &        4    \\\\\n","\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n","\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -57.266   \\\\\n","\\textbf{Date:}            & Tue, 01 Oct 2024 & \\textbf{  Deviance:          } &    114.53   \\\\\n","\\textbf{Time:}            &     17:16:40     & \\textbf{  Pearson chi2:      } &     254.    \\\\\n","\\textbf{No. Iterations:}  &        6         & \\textbf{  Pseudo R-squ. (CS):} &   0.3534    \\\\\n","\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n","\\bottomrule\n","\\end{tabular}\n","\\begin{tabular}{lcccccc}\n","                 & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n","\\midrule\n","\\textbf{const}   &     -10.6490  &        2.588     &    -4.115  &         0.000        &      -15.722    &       -5.576     \\\\\n","\\textbf{Food}    &       0.3818  &        0.148     &     2.572  &         0.010        &        0.091    &        0.673     \\\\\n","\\textbf{Decor}   &       0.0743  &        0.103     &     0.720  &         0.471        &       -0.128    &        0.277     \\\\\n","\\textbf{Service} &      -0.1569  &        0.147     &    -1.070  &         0.285        &       -0.444    &        0.131     \\\\\n","\\textbf{Price}   &       0.0819  &        0.036     &     2.269  &         0.023        &        0.011    &        0.153     \\\\\n","\\bottomrule\n","\\end{tabular}\n","%\\caption{Generalized Linear Model Regression Results}\n","\\end{center}"],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                 Generalized Linear Model Regression Results                  \n","==============================================================================\n","Dep. Variable:             InMichelin   No. Observations:                  123\n","Model:                            GLM   Df Residuals:                      118\n","Model Family:                Binomial   Df Model:                            4\n","Link Function:                  Logit   Scale:                          1.0000\n","Method:                          IRLS   Log-Likelihood:                -57.266\n","Date:                Tue, 01 Oct 2024   Deviance:                       114.53\n","Time:                        17:16:40   Pearson chi2:                     254.\n","No. Iterations:                     6   Pseudo R-squ. (CS):             0.3534\n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          z      P>|z|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const        -10.6490      2.588     -4.115      0.000     -15.722      -5.576\n","Food           0.3818      0.148      2.572      0.010       0.091       0.673\n","Decor          0.0743      0.103      0.720      0.471      -0.128       0.277\n","Service       -0.1569      0.147     -1.070      0.285      -0.444       0.131\n","Price          0.0819      0.036      2.269      0.023       0.011       0.153\n","==============================================================================\n","\"\"\""]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import statsmodels.api as sm\n","\n","# Remember for statsmodels we need to add column of 1's\n","X_train_new = sm.add_constant(X_train)\n","\n","# Generalized Linear Model and binomial family for Logistic regression\n","# Remember for statsmodels that y is passed in before X\n","model = sm.GLM(y_train, X_train_new, family=sm.families.Binomial()).fit()\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"8_VyFy5-IMHc"},"source":["## Logistic Regression with constraints on size of coefficients"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1727803019333,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"7kW-yfnUIMHf","outputId":"cd9ef997-6280-489a-a999-65c5f00271d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["logreg .coef_: [[ 0.38167141  0.07437487 -0.15680599  0.08189124]]\n","Training set score: 0.797\n","Test set score: 0.780\n","logreg.predict: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n"," 1 1 1 1]\n"]}],"source":["# SMALLER C will constrain Betas MORE (opposite of ridge/lasso regression).  It's a tuning parameter we can find using gridsearch.\n","# Note: L2 will shrink coefficients down, never reaching 0. L1 has potential to zero out coefficients\n","\n","# C=100, compare coefs to regular model above.\n","logreg = LogisticRegression(C=100, penalty='l2').fit(X_train, y_train)\n","\n","print(\"logreg .coef_: {}\".format(logreg.coef_))\n","\n","print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n","print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n","\n","predicted_vals = logreg.predict(X_test) # y_pred includes your predictions\n","print(\"logreg.predict: {}\".format(predicted_vals))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":185,"status":"ok","timestamp":1727803028071,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"4RCMm5WCIMHq","outputId":"3e4cd86d-2254-45e8-cb3d-4a0d0dc9c459"},"outputs":[{"name":"stdout","output_type":"stream","text":["logreg .coef_: [[ 0.37185966  0.07491681 -0.14897335  0.08113449]]\n","Training set score: 0.797\n","Test set score: 0.780\n","logreg.predict: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n"," 1 1 1 1]\n"]}],"source":["# Now change to C=1, compare coefs to above models.\n","logreg = LogisticRegression(C=1, penalty='l2').fit(X_train, y_train)\n","\n","print(\"logreg .coef_: {}\".format(logreg .coef_))\n","\n","print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n","print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n","\n","predicted_vals = logreg.predict(X_test) # y_pred includes your predictions\n","print(\"logreg.predict: {}\".format(predicted_vals))"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1727803041548,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"DpGBOiXCIMIf","outputId":"03edbb0e-e42a-46a1-ebf2-15009d80e6f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["logreg .coef_: [[0.00549409 0.00672588 0.00502436 0.02866608]]\n","Training set score: 0.699\n","Test set score: 0.732\n","logreg.predict: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n"," 1 1 0 0]\n"]}],"source":["# Now make C even smaller.  Set C=.0001, compare coefs to above models.\n","# Does the model's prediction power get better or worse??\n","\n","logreg = LogisticRegression(C=.0001, penalty='l2').fit(X_train, y_train)\n","\n","print(\"logreg .coef_: {}\".format(logreg .coef_))\n","\n","print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n","print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n","\n","predicted_vals = logreg.predict(X_test) # y_pred includes your predictions\n","print(\"logreg.predict: {}\".format(predicted_vals))"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169,"status":"ok","timestamp":1727803116974,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"QJlOnuHVnZJd","outputId":"deef3bcd-db7c-45b0-f8ab-5a6120b0d2fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["logreg .coef_: [[-0.02290067  0.          0.          0.00967786]]\n","Training set score: 0.699\n","Test set score: 0.732\n","logreg.predict: [0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0\n"," 1 1 1 1]\n"]}],"source":["# What if we want to use an l1 penalty instead?  Change penalty to 'l1' and solver to 'liblinear'.\n","# Does the model's prediction power get better or worse? Do any coefficients shrink to 0 and drop out of model?\n","# Note: this can be helpful to understand feature importance for additional research.\n","# Solvers are used to optimize parameters of the model. Liblinear is commonly used solver that handles both L1 and L2.\n","\n","logreg = LogisticRegression(C=.01, penalty='l1',solver='liblinear').fit(X_train, y_train)\n","\n","print(\"logreg .coef_: {}\".format(logreg .coef_))\n","\n","print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n","print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n","\n","predicted_vals = logreg.predict(X_test) # y_pred includes your predictions\n","print(\"logreg.predict: {}\".format(predicted_vals))"]},{"cell_type":"markdown","metadata":{"id":"FT3rYS9jIMIn"},"source":["## Multiclass models (Multinomial model)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1727803280785,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"R1JVt7blIMIp","outputId":"1aa26b6c-5b86-45dc-b3ef-ab79abcd5082"},"outputs":[{"name":"stdout","output_type":"stream","text":["['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n","[[5.1 3.5 1.4 0.2]\n"," [4.9 3.  1.4 0.2]\n"," [4.7 3.2 1.3 0.2]\n"," [4.6 3.1 1.5 0.2]\n"," [5.  3.6 1.4 0.2]]\n","['setosa' 'versicolor' 'virginica']\n","[0 1 2]\n"]}],"source":["from sklearn.datasets import load_iris\n","import numpy as np\n","\n","# Three categories for the dependent variable - different iris flower types - setosa, versicolor, virginica\n","iris = load_iris()\n","X, y = iris.data, iris.target\n","\n","print(iris.feature_names ) # X variable names\n","print(X[0:5]) # first five rows of data\n","\n","print(iris.target_names) # target categories\n","print(np.unique(y)) # target values"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":221,"status":"ok","timestamp":1727803421167,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"KuMM3GkSIMIv","outputId":"0db4842a-831f-48e5-e2c2-0ce83dc3450a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n"," 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]}],"source":["# Note the three argument changes to LogisticRegression():\n","# Set to multinomial, change solver to lbfgs, increase iterations\n","\n","logreg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\",max_iter=10000).fit(X,y)\n","print(logreg.predict(X))"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1727803896718,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"037ICwrGIMI_","outputId":"85750ac1-fa03-4063-e29b-f20ad278fb6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.09003057317038046 0.6652409557748219 0.24472847105479767\n","1.0\n"]}],"source":["# Softmax is used for to transform values into predicated probabilities\n","# Softmax is like logistic regression, but multi-class\n","# Here's how Softmax is calculated with some example data...\n","from math import exp\n","\n","# Calculate each probability\n","p1 = exp(1) / (exp(1) + exp(3) + exp(2))\n","p2 = exp(3) / (exp(1) + exp(3) + exp(2))\n","p3 = exp(2) / (exp(1) + exp(3) + exp(2))\n","\n","# Report probabilities\n","print(p1, p2, p3)\n","\n","# Report sum of probabilities\n","print(p1 + p2 + p3)"]},{"cell_type":"markdown","metadata":{"id":"CiC9t9fS9kKN"},"source":["## Alternative scoring metrics"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":175,"status":"ok","timestamp":1727803997774,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"nkES0i_a9kSM","outputId":"741ed33a-4627-473b-dca2-0541714490ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9666666666666666\n","R-squared: 0.95\n"]}],"source":["# Use the scoring argument in cross_val_score() to adjust metrics\n","from sklearn import svm, datasets\n","from sklearn.model_selection import cross_val_score\n","\n","iris = datasets.load_iris()\n","X, y = iris.data, iris.target\n","clf = svm.SVC(probability=True, random_state=0)\n","\n","# For now we will use 'accuracy' for classification models and r-squared in regression models\n","print(f'Accuracy: {cross_val_score(clf, X, y, scoring=\"accuracy\").mean()}')\n","print(f'R-squared: {cross_val_score(clf, X, y, scoring=\"r2\").mean()}')"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1727804011230,"user":{"displayName":"Mazen Asaad","userId":"15315554018675229727"},"user_tz":240},"id":"ML38BLXzxgXW","outputId":"928cc587-1bad-4e67-debb-5539823568a7"},"outputs":[{"data":{"text/plain":["['accuracy',\n"," 'adjusted_mutual_info_score',\n"," 'adjusted_rand_score',\n"," 'average_precision',\n"," 'balanced_accuracy',\n"," 'completeness_score',\n"," 'd2_absolute_error_score',\n"," 'explained_variance',\n"," 'f1',\n"," 'f1_macro',\n"," 'f1_micro',\n"," 'f1_samples',\n"," 'f1_weighted',\n"," 'fowlkes_mallows_score',\n"," 'homogeneity_score',\n"," 'jaccard',\n"," 'jaccard_macro',\n"," 'jaccard_micro',\n"," 'jaccard_samples',\n"," 'jaccard_weighted',\n"," 'matthews_corrcoef',\n"," 'max_error',\n"," 'mutual_info_score',\n"," 'neg_brier_score',\n"," 'neg_log_loss',\n"," 'neg_mean_absolute_error',\n"," 'neg_mean_absolute_percentage_error',\n"," 'neg_mean_gamma_deviance',\n"," 'neg_mean_poisson_deviance',\n"," 'neg_mean_squared_error',\n"," 'neg_mean_squared_log_error',\n"," 'neg_median_absolute_error',\n"," 'neg_negative_likelihood_ratio',\n"," 'neg_root_mean_squared_error',\n"," 'neg_root_mean_squared_log_error',\n"," 'normalized_mutual_info_score',\n"," 'positive_likelihood_ratio',\n"," 'precision',\n"," 'precision_macro',\n"," 'precision_micro',\n"," 'precision_samples',\n"," 'precision_weighted',\n"," 'r2',\n"," 'rand_score',\n"," 'recall',\n"," 'recall_macro',\n"," 'recall_micro',\n"," 'recall_samples',\n"," 'recall_weighted',\n"," 'roc_auc',\n"," 'roc_auc_ovo',\n"," 'roc_auc_ovo_weighted',\n"," 'roc_auc_ovr',\n"," 'roc_auc_ovr_weighted',\n"," 'top_k_accuracy',\n"," 'v_measure_score']"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["# See all possible options\n","from sklearn import metrics\n","metrics.get_scorer_names()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":0}
